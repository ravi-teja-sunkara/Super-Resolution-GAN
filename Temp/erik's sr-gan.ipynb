{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-byxWkTp1lH",
        "colab_type": "code",
        "outputId": "4ba946a0-b4bc-439c-e56f-bb67c1219c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwRZCJSMrK0D",
        "colab_type": "code",
        "outputId": "f10d80c1-f01c-47e8-899c-75674af87c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t5aktOgp5uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  \n",
        "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"test\"\n",
        "        \n",
        "        path = glob('./drive/My Drive/Colab Notebooks/%s/*' % (self.dataset_name))\n",
        "\n",
        "#         path = './drive/My Drive/Colab Notebooks/Dataset_srgan_flicker'\n",
        "        \n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs_hr = []\n",
        "        imgs_lr = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "\n",
        "            h, w = self.img_res\n",
        "            low_h, low_w = int(h / 4), int(w / 4)\n",
        "\n",
        "            img_hr = scipy.misc.imresize(img, self.img_res)\n",
        "            img_lr = scipy.misc.imresize(img, (low_h, low_w))\n",
        "\n",
        "            # If training => do random flip\n",
        "            if not is_testing and np.random.random() < 0.5:\n",
        "                img_hr = np.fliplr(img_hr)\n",
        "                img_lr = np.fliplr(img_lr)\n",
        "\n",
        "            imgs_hr.append(img_hr)\n",
        "            imgs_lr.append(img_lr)\n",
        "\n",
        "        imgs_hr = np.array(imgs_hr) / 127.5 - 1.\n",
        "        imgs_lr = np.array(imgs_lr) / 127.5 - 1.\n",
        "\n",
        "        return imgs_hr, imgs_lr\n",
        "\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwcdo9ssrOhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SRGAN():\n",
        "  def __init__(self):\n",
        "      # Input shape\n",
        "      self.channels = 3\n",
        "      self.lr_height = 56                 # Low resolution height\n",
        "      self.lr_width = 56                 # Low resolution width\n",
        "      self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n",
        "      self.hr_height = self.lr_height*4   # High resolution height\n",
        "      self.hr_width = self.lr_width*4     # High resolution width\n",
        "      self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n",
        "\n",
        "      # Number of residual blocks in the generator\n",
        "      self.n_residual_blocks = 16\n",
        "\n",
        "      optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "      # We use a pre-trained VGG19 model to extract image features from the high resolution\n",
        "      # and the generated high resolution images and minimize the mse between them\n",
        "      self.vgg = self.build_vgg()\n",
        "      self.vgg.trainable = False\n",
        "      self.vgg.compile(loss='mse',\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "      # Configure data loader\n",
        "      self.dataset_name = 'Dataset_srgan_flicker/Flickr2K'\n",
        "      self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
        "                                    img_res=(self.hr_height, self.hr_width))\n",
        "\n",
        "      # Calculate output shape of D (PatchGAN)\n",
        "      patch = int(self.hr_height / 2**4)\n",
        "      self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "      # Number of filters in the first layer of G and D\n",
        "      self.gf = 64\n",
        "      self.df = 64\n",
        "\n",
        "      # Build and compile the discriminator\n",
        "      self.discriminator = self.build_discriminator()\n",
        "      self.discriminator.compile(loss='mse',\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "      # Build the generator\n",
        "      self.generator = self.build_generator()\n",
        "\n",
        "      # High res. and low res. images\n",
        "      img_hr = Input(shape=self.hr_shape)\n",
        "      img_lr = Input(shape=self.lr_shape)\n",
        "\n",
        "      # Generate high res. version from low res.\n",
        "      fake_hr = self.generator(img_lr)\n",
        "\n",
        "      # Extract image features of the generated img\n",
        "      fake_features = self.vgg(fake_hr)\n",
        "\n",
        "      # For the combined model we will only train the generator\n",
        "      self.discriminator.trainable = False\n",
        "\n",
        "      # Discriminator determines validity of generated high res. images\n",
        "      validity = self.discriminator(fake_hr)\n",
        "\n",
        "      self.combined = Model([img_lr, img_hr], [validity, fake_features])\n",
        "      self.combined.compile(loss=['binary_crossentropy', 'mse'],\n",
        "                            loss_weights=[1e-3, 1],\n",
        "                            optimizer=optimizer)\n",
        "        \n",
        "  def build_vgg(self):\n",
        "\n",
        "    vgg = VGG19(weights=\"imagenet\")\n",
        "    # Set outputs to outputs of last conv. layer in block 3\n",
        "    # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
        "    vgg.outputs = [vgg.layers[9].output]\n",
        "\n",
        "    img = Input(shape=self.hr_shape)\n",
        "\n",
        "    # Extract image features\n",
        "    img_features = vgg(img)\n",
        "\n",
        "    return Model(img, img_features)\n",
        "\n",
        "  def build_generator(self):\n",
        "    def residual_block(layer_input, filters):\n",
        "      \"\"\"Residual block described in paper\"\"\"\n",
        "      d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
        "      d = Activation('relu')(d)\n",
        "      d = BatchNormalization(momentum=0.8)(d)\n",
        "      d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
        "      d = BatchNormalization(momentum=0.8)(d)\n",
        "      d = Add()([d, layer_input])\n",
        "      return d\n",
        "\n",
        "  def build_generator(self):\n",
        "\n",
        "    def residual_block(layer_input, filters):\n",
        "        \"\"\"Residual block described in paper\"\"\"\n",
        "        d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
        "        d = Activation('relu')(d)\n",
        "        d = BatchNormalization(momentum=0.8)(d)\n",
        "        d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
        "        d = BatchNormalization(momentum=0.8)(d)\n",
        "        d = Add()([d, layer_input])\n",
        "        return d\n",
        "\n",
        "    def deconv2d(layer_input):\n",
        "        \"\"\"Layers used during upsampling\"\"\"\n",
        "        u = UpSampling2D(size=2)(layer_input)\n",
        "        u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
        "        u = Activation('relu')(u)\n",
        "        return u\n",
        "\n",
        "    # Low resolution image input\n",
        "    img_lr = Input(shape=self.lr_shape)\n",
        "\n",
        "    # Pre-residual block\n",
        "    c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)\n",
        "    c1 = Activation('relu')(c1)\n",
        "\n",
        "    # Propogate through residual blocks\n",
        "    r = residual_block(c1, self.gf)\n",
        "    for _ in range(self.n_residual_blocks - 1):\n",
        "        r = residual_block(r, self.gf)\n",
        "\n",
        "    # Post-residual block\n",
        "    c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
        "    c2 = BatchNormalization(momentum=0.8)(c2)\n",
        "    c2 = Add()([c2, c1])\n",
        "\n",
        "    # Upsampling\n",
        "    u1 = deconv2d(c2)\n",
        "    u2 = deconv2d(u1)\n",
        "\n",
        "    # Generate high resolution output\n",
        "    gen_hr = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)\n",
        "\n",
        "    return Model(img_lr, gen_hr)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "\n",
        "    def d_block(layer_input, filters, strides=1, bn=True):\n",
        "        \"\"\"Discriminator layer\"\"\"\n",
        "        d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
        "        d = LeakyReLU(alpha=0.2)(d)\n",
        "        if bn:\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "        return d\n",
        "\n",
        "    # Input img\n",
        "    d0 = Input(shape=self.hr_shape)\n",
        "\n",
        "    d1 = d_block(d0, self.df, bn=False)\n",
        "    d2 = d_block(d1, self.df, strides=2)\n",
        "    d3 = d_block(d2, self.df*2)\n",
        "    d4 = d_block(d3, self.df*2, strides=2)\n",
        "    d5 = d_block(d4, self.df*4)\n",
        "    d6 = d_block(d5, self.df*4, strides=2)\n",
        "    d7 = d_block(d6, self.df*8)\n",
        "    d8 = d_block(d7, self.df*8, strides=2)\n",
        "\n",
        "    d9 = Dense(self.df*16)(d8)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "    return Model(d0, validity)\n",
        "\n",
        "  def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ----------------------\n",
        "            #  Train Discriminator\n",
        "            # ----------------------\n",
        "\n",
        "            # Sample images and their conditioning counterparts\n",
        "            imgs_hr, imgs_lr = self.data_loader.load_data(batch_size)\n",
        "\n",
        "            # From low res. image generate high res. version\n",
        "            fake_hr = self.generator.predict(imgs_lr)\n",
        "\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\n",
        "            # Train the discriminators (original images = real / generated = Fake)\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs_hr, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(fake_hr, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ------------------\n",
        "            #  Train Generator\n",
        "            # ------------------\n",
        "\n",
        "            # Sample images and their conditioning counterparts\n",
        "            imgs_hr, imgs_lr = self.data_loader.load_data(batch_size)\n",
        "\n",
        "            # The generators want the discriminators to label the generated images as real\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "\n",
        "            # Extract ground truth image features using pre-trained VGG19 model\n",
        "            image_features = self.vgg.predict(imgs_hr)\n",
        "\n",
        "            # Train the generators\n",
        "            g_loss = self.combined.train_on_batch([imgs_lr, imgs_hr], [valid, image_features])\n",
        "\n",
        "            elapsed_time = datetime.datetime.now() - start_time\n",
        "            # Plot the progress\n",
        "            print (\"%d time: %s\" % (epoch, elapsed_time))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "                \n",
        "  def sample_images(self, epoch):\n",
        "        os.makedirs('./drive/My Drive/Colab Notebooks/Dataset_srgan_flicker/images/%s' % self.dataset_name, exist_ok=True)\n",
        "        r, c = 2, 2\n",
        "\n",
        "        imgs_hr, imgs_lr = self.data_loader.load_data(batch_size=2, is_testing=True)\n",
        "        fake_hr = self.generator.predict(imgs_lr)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        imgs_lr = 0.5 * imgs_lr + 0.5\n",
        "        fake_hr = 0.5 * fake_hr + 0.5\n",
        "        imgs_hr = 0.5 * imgs_hr + 0.5\n",
        "\n",
        "        # Save generated images and the high resolution originals\n",
        "        titles = ['Generated', 'Original']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for row in range(r):\n",
        "            for col, image in enumerate([fake_hr, imgs_hr]):\n",
        "                axs[row, col].imshow(image[row])\n",
        "                axs[row, col].set_title(titles[col])\n",
        "                axs[row, col].axis('off')\n",
        "            cnt += 1\n",
        "        fig.savefig(\"./drive/My Drive/Colab Notebooks/Dataset_srgan_flicker/images/%s/%d.png\" % (self.dataset_name, epoch))\n",
        "        plt.close()\n",
        "\n",
        "        # Save low resolution images for comparison\n",
        "        for i in range(r):\n",
        "            fig = plt.figure()\n",
        "            plt.imshow(imgs_lr[i])\n",
        "            fig.savefig('./drive/My Drive/Colab Notebooks/Dataset_srgan_flicker/images/%s/%d_lowres%d.png' % (self.dataset_name, epoch, i))\n",
        "            plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxFG2UxwwWCb",
        "colab_type": "code",
        "outputId": "314b3ec7-45ad-4ee7-ee54-64a300cc1afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1902
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    gan = SRGAN()\n",
        "    gan.train(epochs=100, batch_size=1, sample_interval=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 time: 0:00:42.710355\n",
            "1 time: 0:00:46.502968\n",
            "2 time: 0:00:48.126709\n",
            "3 time: 0:00:49.813581\n",
            "4 time: 0:00:52.295116\n",
            "5 time: 0:00:54.435110\n",
            "6 time: 0:00:56.000825\n",
            "7 time: 0:00:57.155279\n",
            "8 time: 0:00:58.985981\n",
            "9 time: 0:01:00.438785\n",
            "10 time: 0:01:02.002566\n",
            "11 time: 0:01:03.645074\n",
            "12 time: 0:01:05.035473\n",
            "13 time: 0:01:06.650414\n",
            "14 time: 0:01:08.229885\n",
            "15 time: 0:01:09.404139\n",
            "16 time: 0:01:11.014844\n",
            "17 time: 0:01:12.646029\n",
            "18 time: 0:01:14.187328\n",
            "19 time: 0:01:15.684512\n",
            "20 time: 0:01:17.108318\n",
            "21 time: 0:01:18.343940\n",
            "22 time: 0:01:19.954897\n",
            "23 time: 0:01:21.427572\n",
            "24 time: 0:01:23.011268\n",
            "25 time: 0:01:24.455637\n",
            "26 time: 0:01:26.142060\n",
            "27 time: 0:01:27.837007\n",
            "28 time: 0:01:29.146778\n",
            "29 time: 0:01:30.650953\n",
            "30 time: 0:01:32.320270\n",
            "31 time: 0:01:34.142037\n",
            "32 time: 0:01:35.935102\n",
            "33 time: 0:01:37.704305\n",
            "34 time: 0:01:39.195236\n",
            "35 time: 0:01:40.967598\n",
            "36 time: 0:01:42.428363\n",
            "37 time: 0:01:44.125872\n",
            "38 time: 0:01:45.629695\n",
            "39 time: 0:01:47.301392\n",
            "40 time: 0:01:48.936779\n",
            "41 time: 0:01:50.599855\n",
            "42 time: 0:01:52.069768\n",
            "43 time: 0:01:53.937143\n",
            "44 time: 0:01:55.616877\n",
            "45 time: 0:01:56.962345\n",
            "46 time: 0:01:58.605264\n",
            "47 time: 0:02:00.450496\n",
            "48 time: 0:02:02.155861\n",
            "49 time: 0:02:03.909738\n",
            "50 time: 0:02:05.881977\n",
            "51 time: 0:02:09.620752\n",
            "52 time: 0:02:11.651801\n",
            "53 time: 0:02:13.275047\n",
            "54 time: 0:02:15.075797\n",
            "55 time: 0:02:16.909655\n",
            "56 time: 0:02:18.469624\n",
            "57 time: 0:02:19.917627\n",
            "58 time: 0:02:21.660413\n",
            "59 time: 0:02:23.411661\n",
            "60 time: 0:02:25.218152\n",
            "61 time: 0:02:26.758274\n",
            "62 time: 0:02:28.191639\n",
            "63 time: 0:02:29.813356\n",
            "64 time: 0:02:31.551195\n",
            "65 time: 0:02:32.991248\n",
            "66 time: 0:02:34.376891\n",
            "67 time: 0:02:35.743527\n",
            "68 time: 0:02:37.874908\n",
            "69 time: 0:02:39.336169\n",
            "70 time: 0:02:40.963594\n",
            "71 time: 0:02:42.607268\n",
            "72 time: 0:02:44.447562\n",
            "73 time: 0:02:46.064691\n",
            "74 time: 0:02:47.419449\n",
            "75 time: 0:02:48.780886\n",
            "76 time: 0:02:50.226454\n",
            "77 time: 0:02:51.846088\n",
            "78 time: 0:02:53.088313\n",
            "79 time: 0:02:54.778315\n",
            "80 time: 0:02:55.837499\n",
            "81 time: 0:02:57.465032\n",
            "82 time: 0:02:59.217698\n",
            "83 time: 0:03:00.870629\n",
            "84 time: 0:03:02.611050\n",
            "85 time: 0:03:04.283323\n",
            "86 time: 0:03:06.119327\n",
            "87 time: 0:03:07.794257\n",
            "88 time: 0:03:09.013912\n",
            "89 time: 0:03:10.855859\n",
            "90 time: 0:03:12.419684\n",
            "91 time: 0:03:14.025240\n",
            "92 time: 0:03:15.885568\n",
            "93 time: 0:03:17.509687\n",
            "94 time: 0:03:19.059137\n",
            "95 time: 0:03:20.954924\n",
            "96 time: 0:03:22.407535\n",
            "97 time: 0:03:24.647170\n",
            "98 time: 0:03:26.356255\n",
            "99 time: 0:03:27.840522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NRAOFXZ9jIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}